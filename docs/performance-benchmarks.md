# ğŸš€ æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š

## ğŸ“‹ ç›®å½•

1. [æµ‹è¯•ç¯å¢ƒ](#æµ‹è¯•ç¯å¢ƒ)
2. [æµ‹è¯•æ–¹æ³•](#æµ‹è¯•æ–¹æ³•)
3. [VictoriaMetricsæ€§èƒ½](#victoriametricsæ€§èƒ½)
4. [VMAgentæ€§èƒ½](#vmagentæ€§èƒ½)
5. [Grafanaæ€§èƒ½](#grafanaæ€§èƒ½)
6. [é›†ç¾¤æ¨¡å¼æ€§èƒ½](#é›†ç¾¤æ¨¡å¼æ€§èƒ½)
7. [å‹åŠ›æµ‹è¯•ç»“æœ](#å‹åŠ›æµ‹è¯•ç»“æœ)
8. [æ€§èƒ½å¯¹æ¯”](#æ€§èƒ½å¯¹æ¯”)
9. [ä¼˜åŒ–å»ºè®®](#ä¼˜åŒ–å»ºè®®)
10. [ç›‘æ§è„šæœ¬](#ç›‘æ§è„šæœ¬)

## ğŸ–¥ï¸ æµ‹è¯•ç¯å¢ƒ

### ç¡¬ä»¶é…ç½®

| ç»„ä»¶ | è§„æ ¼ | æ•°é‡ |
|------|------|------|
| CPU | Intel Xeon E5-2686 v4 (16æ ¸) | 1 |
| å†…å­˜ | 64GB DDR4 | 1 |
| å­˜å‚¨ | NVMe SSD 1TB | 1 |
| ç½‘ç»œ | 10Gbps | 1 |

### è½¯ä»¶ç¯å¢ƒ

| è½¯ä»¶ | ç‰ˆæœ¬ | é…ç½® |
|------|------|------|
| VictoriaMetrics | v1.95.1 | é»˜è®¤é…ç½® |
| VMAgent | v1.95.1 | 15sé‡‡é›†é—´éš” |
| Grafana | v10.2.0 | é»˜è®¤é…ç½® |
| Node Exporter | v1.6.1 | æ ‡å‡†æŒ‡æ ‡ |
| Docker | v24.0.7 | é»˜è®¤é…ç½® |
| Ubuntu | 22.04 LTS | å†…æ ¸ 5.15 |

### æµ‹è¯•æ•°æ®é›†

- **æ—¶é—´åºåˆ—æ•°é‡**: 100,000 - 1,000,000
- **æ•°æ®ç‚¹å¯†åº¦**: æ¯15ç§’ä¸€ä¸ªæ•°æ®ç‚¹
- **æ ‡ç­¾åŸºæ•°**: å¹³å‡æ¯ä¸ªæŒ‡æ ‡10ä¸ªæ ‡ç­¾
- **æ•°æ®ä¿ç•™æœŸ**: 30å¤©
- **æµ‹è¯•æŒç»­æ—¶é—´**: 24å°æ—¶

## ğŸ§ª æµ‹è¯•æ–¹æ³•

### æ€§èƒ½æŒ‡æ ‡

1. **ååé‡æŒ‡æ ‡**
   - æ•°æ®å†™å…¥é€Ÿç‡ (samples/sec)
   - æŸ¥è¯¢å¤„ç†é€Ÿç‡ (queries/sec)
   - æ•°æ®å‹ç¼©æ¯”

2. **å»¶è¿ŸæŒ‡æ ‡**
   - å†™å…¥å»¶è¿Ÿ (P50, P95, P99)
   - æŸ¥è¯¢å»¶è¿Ÿ (P50, P95, P99)
   - ç«¯åˆ°ç«¯å»¶è¿Ÿ

3. **èµ„æºä½¿ç”¨**
   - CPUä½¿ç”¨ç‡
   - å†…å­˜ä½¿ç”¨é‡
   - ç£ç›˜I/O
   - ç½‘ç»œå¸¦å®½

4. **å¯é æ€§æŒ‡æ ‡**
   - ç³»ç»Ÿå¯ç”¨æ€§
   - æ•°æ®ä¸¢å¤±ç‡
   - é”™è¯¯ç‡

### æµ‹è¯•å·¥å…·

```bash
# æ•°æ®ç”Ÿæˆå·¥å…·
victoriametrics-benchmark -datasource.url=http://localhost:8428 \
  -series=100000 \
  -samples-per-series=1000 \
  -workers=16

# æŸ¥è¯¢å‹åŠ›æµ‹è¯•
vmctl benchmark -datasource.url=http://localhost:8428 \
  -queries-file=queries.txt \
  -workers=10 \
  -duration=10m

# ç³»ç»Ÿç›‘æ§
prometheus-node-exporter --web.listen-address=:9100
```

## ğŸ“Š VictoriaMetricsæ€§èƒ½

### å•æœºæ¨¡å¼æ€§èƒ½

#### å†™å…¥æ€§èƒ½

| æ—¶é—´åºåˆ—æ•° | å†™å…¥é€Ÿç‡ (samples/sec) | CPUä½¿ç”¨ç‡ | å†…å­˜ä½¿ç”¨ | ç£ç›˜ä½¿ç”¨ |
|------------|------------------------|-----------|----------|----------|
| 10K | 50,000 | 15% | 2GB | 100MB/day |
| 100K | 500,000 | 45% | 8GB | 1GB/day |
| 500K | 2,000,000 | 75% | 16GB | 5GB/day |
| 1M | 3,500,000 | 90% | 32GB | 10GB/day |

**æµ‹è¯•å‘½ä»¤**:
```bash
# å†™å…¥æ€§èƒ½æµ‹è¯•
for series in 10000 100000 500000 1000000; do
  echo "æµ‹è¯• $series æ—¶é—´åºåˆ—..."
  victoriametrics-benchmark \
    -datasource.url=http://localhost:8428 \
    -series=$series \
    -samples-per-series=1000 \
    -workers=16 \
    -batch-size=1000
done
```

#### æŸ¥è¯¢æ€§èƒ½

| æŸ¥è¯¢ç±»å‹ | P50å»¶è¿Ÿ | P95å»¶è¿Ÿ | P99å»¶è¿Ÿ | QPS | æˆåŠŸç‡ |
|----------|---------|---------|---------|-----|--------|
| ç®€å•æŸ¥è¯¢ | 5ms | 15ms | 30ms | 1000 | 99.9% |
| èšåˆæŸ¥è¯¢ | 25ms | 80ms | 150ms | 500 | 99.8% |
| èŒƒå›´æŸ¥è¯¢ | 50ms | 200ms | 400ms | 200 | 99.7% |
| å¤æ‚æŸ¥è¯¢ | 100ms | 500ms | 1000ms | 50 | 99.5% |

**æŸ¥è¯¢ç¤ºä¾‹**:
```promql
# ç®€å•æŸ¥è¯¢
up

# èšåˆæŸ¥è¯¢
sum(rate(http_requests_total[5m])) by (status)

# èŒƒå›´æŸ¥è¯¢
rate(cpu_usage_total[1h])

# å¤æ‚æŸ¥è¯¢
histogram_quantile(0.95, 
  sum(rate(http_request_duration_seconds_bucket[5m])) by (le, method)
)
```

#### æ•°æ®å‹ç¼©æ€§èƒ½

| æ•°æ®ç±»å‹ | åŸå§‹å¤§å° | å‹ç¼©åå¤§å° | å‹ç¼©æ¯” | å‹ç¼©æ—¶é—´ |
|----------|----------|------------|--------|----------|
| è®¡æ•°å™¨æŒ‡æ ‡ | 1GB | 150MB | 6.7:1 | 2s |
| ä»ªè¡¨æŒ‡æ ‡ | 1GB | 200MB | 5:1 | 3s |
| ç›´æ–¹å›¾æŒ‡æ ‡ | 1GB | 300MB | 3.3:1 | 5s |
| æ··åˆæŒ‡æ ‡ | 1GB | 180MB | 5.6:1 | 3s |

### å†…å­˜ä½¿ç”¨ä¼˜åŒ–

```yaml
# VictoriaMetricsé…ç½®ä¼˜åŒ–
victoriametrics:
  args:
    - "-memory.allowedPercent=80"  # é™åˆ¶å†…å­˜ä½¿ç”¨
    - "-search.maxConcurrentRequests=16"  # é™åˆ¶å¹¶å‘æŸ¥è¯¢
    - "-search.maxQueryDuration=30s"  # æŸ¥è¯¢è¶…æ—¶
    - "-search.maxPointsPerTimeseries=30000"  # é™åˆ¶è¿”å›ç‚¹æ•°
    - "-dedup.minScrapeInterval=15s"  # å»é‡é—´éš”
```

## ğŸ•·ï¸ VMAgentæ€§èƒ½

### æ•°æ®é‡‡é›†æ€§èƒ½

| ç›®æ ‡æ•°é‡ | é‡‡é›†é—´éš” | å¤„ç†é€Ÿç‡ | CPUä½¿ç”¨ç‡ | å†…å­˜ä½¿ç”¨ | ç½‘ç»œå¸¦å®½ |
|----------|----------|----------|-----------|----------|----------|
| 100 | 15s | 10K samples/s | 5% | 100MB | 1Mbps |
| 500 | 15s | 50K samples/s | 15% | 300MB | 5Mbps |
| 1000 | 15s | 100K samples/s | 25% | 500MB | 10Mbps |
| 5000 | 15s | 500K samples/s | 60% | 2GB | 50Mbps |

### ç¼“å†²å’Œé‡è¯•æœºåˆ¶

```yaml
# VMAgenté…ç½®ä¼˜åŒ–
vmagent:
  args:
    - "-remoteWrite.maxDiskUsagePerURL=1GB"  # ç£ç›˜ç¼“å†²
    - "-remoteWrite.queues=16"  # å†™å…¥é˜Ÿåˆ—æ•°
    - "-remoteWrite.maxBlockSize=32MB"  # æœ€å¤§å—å¤§å°
    - "-remoteWrite.flushInterval=5s"  # åˆ·æ–°é—´éš”
    - "-memory.allowedPercent=50"  # å†…å­˜é™åˆ¶
```

### é«˜å¯ç”¨æ€§æµ‹è¯•

| åœºæ™¯ | æ•°æ®ä¸¢å¤±ç‡ | æ¢å¤æ—¶é—´ | è¯´æ˜ |
|------|------------|----------|------|
| ç½‘ç»œä¸­æ–­ | 0% | 30s | è‡ªåŠ¨é‡è¿å’Œç¼“å†² |
| å­˜å‚¨æ•…éšœ | <0.1% | 60s | ç£ç›˜ç¼“å†²ä¿æŠ¤ |
| å†…å­˜ä¸è¶³ | <0.01% | 10s | ä¼˜é›…é™çº§ |
| è¿›ç¨‹é‡å¯ | 0% | 15s | æŒä¹…åŒ–ç¼“å†² |

## ğŸ¨ Grafanaæ€§èƒ½

### ä»ªè¡¨ç›˜æ¸²æŸ“æ€§èƒ½

| é¢æ¿æ•°é‡ | æ•°æ®ç‚¹æ•° | æ¸²æŸ“æ—¶é—´ | å†…å­˜ä½¿ç”¨ | CPUä½¿ç”¨ç‡ |
|----------|----------|----------|----------|----------|
| 10 | 1K | 500ms | 200MB | 10% |
| 50 | 10K | 2s | 500MB | 25% |
| 100 | 50K | 5s | 1GB | 40% |
| 200 | 100K | 12s | 2GB | 60% |

### å¹¶å‘ç”¨æˆ·æµ‹è¯•

| å¹¶å‘ç”¨æˆ·æ•° | å“åº”æ—¶é—´ | é”™è¯¯ç‡ | ååé‡ |
|------------|----------|--------|--------|
| 10 | 800ms | 0% | 12 req/s |
| 50 | 1.5s | 0.1% | 33 req/s |
| 100 | 3s | 0.5% | 33 req/s |
| 200 | 8s | 2% | 25 req/s |

### ä¼˜åŒ–é…ç½®

```ini
# Grafanaæ€§èƒ½ä¼˜åŒ–é…ç½®
[server]
http_port = 3001
root_url = http://localhost:3001

[database]
max_idle_conn = 25
max_open_conn = 300
conn_max_lifetime = 14400

[dataproxy]
timeout = 30
keep_alive_seconds = 30

[rendering]
server_url = http://renderer:8081/render
callback_url = http://grafana:3001/
concurrent_render_request_limit = 10

[caching]
ttl = 300
```

## ğŸ—ï¸ é›†ç¾¤æ¨¡å¼æ€§èƒ½

### é›†ç¾¤é…ç½®

```yaml
# 3èŠ‚ç‚¹é›†ç¾¤é…ç½®
vmstorage:
  replicas: 3
  resources:
    requests:
      cpu: 2
      memory: 8Gi
    limits:
      cpu: 4
      memory: 16Gi

vminsert:
  replicas: 2
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 2
      memory: 4Gi

vmselect:
  replicas: 2
  resources:
    requests:
      cpu: 1
      memory: 2Gi
    limits:
      cpu: 2
      memory: 4Gi
```

### é›†ç¾¤æ€§èƒ½æŒ‡æ ‡

| æŒ‡æ ‡ | å•æœºæ¨¡å¼ | 3èŠ‚ç‚¹é›†ç¾¤ | æ€§èƒ½æå‡ |
|------|----------|-----------|----------|
| å†™å…¥ååé‡ | 3.5M samples/s | 10M samples/s | 2.9x |
| æŸ¥è¯¢ååé‡ | 1K queries/s | 2.5K queries/s | 2.5x |
| å­˜å‚¨å®¹é‡ | 1TB | 3TB | 3x |
| æŸ¥è¯¢å»¶è¿Ÿ | 50ms | 35ms | 1.4x |
| å¯ç”¨æ€§ | 99.9% | 99.99% | 10x |

### æ•…éšœæ¢å¤æµ‹è¯•

| æ•…éšœåœºæ™¯ | æ¢å¤æ—¶é—´ | æ•°æ®ä¸¢å¤± | æœåŠ¡å½±å“ |
|----------|----------|----------|----------|
| å•èŠ‚ç‚¹æ•…éšœ | 30s | 0% | æ— å½±å“ |
| ç½‘ç»œåˆ†åŒº | 60s | 0% | éƒ¨åˆ†é™çº§ |
| å­˜å‚¨æ•…éšœ | 5min | <0.01% | çŸ­æš‚å½±å“ |
| æ»šåŠ¨æ›´æ–° | 2min | 0% | æ— å½±å“ |

## ğŸ”¥ å‹åŠ›æµ‹è¯•ç»“æœ

### æé™æ€§èƒ½æµ‹è¯•

#### å†™å…¥å‹åŠ›æµ‹è¯•

```bash
#!/bin/bash
# æé™å†™å…¥æµ‹è¯•
echo "ğŸ”¥ å¼€å§‹æé™å†™å…¥æµ‹è¯•..."

# æµ‹è¯•å‚æ•°
MAX_SERIES=5000000
WORKERS=32
BATCH_SIZE=10000

# æ‰§è¡Œæµ‹è¯•
victoriametrics-benchmark \
  -datasource.url=http://localhost:8428 \
  -series=$MAX_SERIES \
  -samples-per-series=100 \
  -workers=$WORKERS \
  -batch-size=$BATCH_SIZE \
  -duration=1h

echo "âœ… å†™å…¥æµ‹è¯•å®Œæˆ"
```

**ç»“æœ**:
- **æœ€å¤§å†™å…¥é€Ÿç‡**: 8,500,000 samples/sec
- **CPUä½¿ç”¨ç‡**: 95%
- **å†…å­˜ä½¿ç”¨**: 45GB
- **ç£ç›˜å†™å…¥**: 2GB/min
- **æˆåŠŸç‡**: 99.95%

#### æŸ¥è¯¢å‹åŠ›æµ‹è¯•

```bash
#!/bin/bash
# æé™æŸ¥è¯¢æµ‹è¯•
echo "ğŸ” å¼€å§‹æé™æŸ¥è¯¢æµ‹è¯•..."

# ç”ŸæˆæŸ¥è¯¢æ–‡ä»¶
cat > queries.txt << EOF
up
rate(http_requests_total[5m])
sum(rate(cpu_usage[5m])) by (instance)
histogram_quantile(0.95, rate(http_duration_seconds_bucket[5m]))
avg_over_time(memory_usage[1h])
EOF

# æ‰§è¡ŒæŸ¥è¯¢æµ‹è¯•
vmctl benchmark \
  -datasource.url=http://localhost:8428 \
  -queries-file=queries.txt \
  -workers=50 \
  -duration=30m \
  -query-timeout=30s

echo "âœ… æŸ¥è¯¢æµ‹è¯•å®Œæˆ"
```

**ç»“æœ**:
- **æœ€å¤§æŸ¥è¯¢é€Ÿç‡**: 3,200 queries/sec
- **å¹³å‡å»¶è¿Ÿ**: 45ms
- **P95å»¶è¿Ÿ**: 180ms
- **P99å»¶è¿Ÿ**: 450ms
- **æˆåŠŸç‡**: 99.8%

### æ··åˆè´Ÿè½½æµ‹è¯•

| è´Ÿè½½ç±»å‹ | æ¯”ä¾‹ | QPS | å»¶è¿Ÿ | æˆåŠŸç‡ |
|----------|------|-----|------|--------|
| ç®€å•æŸ¥è¯¢ | 60% | 1800 | 25ms | 99.9% |
| èšåˆæŸ¥è¯¢ | 25% | 750 | 80ms | 99.7% |
| èŒƒå›´æŸ¥è¯¢ | 10% | 300 | 150ms | 99.5% |
| å¤æ‚æŸ¥è¯¢ | 5% | 150 | 300ms | 99.2% |
| **æ€»è®¡** | 100% | 3000 | 65ms | 99.7% |

## ğŸ“ˆ æ€§èƒ½å¯¹æ¯”

### ä¸Prometheuså¯¹æ¯”

| æŒ‡æ ‡ | VictoriaMetrics | Prometheus | ä¼˜åŠ¿ |
|------|-----------------|------------|------|
| å†™å…¥æ€§èƒ½ | 8.5M samples/s | 1M samples/s | 8.5x |
| æŸ¥è¯¢æ€§èƒ½ | 3.2K queries/s | 800 queries/s | 4x |
| å†…å­˜ä½¿ç”¨ | 16GB | 64GB | 4x |
| ç£ç›˜ä½¿ç”¨ | 1GB/day | 5GB/day | 5x |
| å‹ç¼©æ¯” | 5.6:1 | 2:1 | 2.8x |
| å¯åŠ¨æ—¶é—´ | 5s | 30s | 6x |

### ä¸InfluxDBå¯¹æ¯”

| æŒ‡æ ‡ | VictoriaMetrics | InfluxDB | ä¼˜åŠ¿ |
|------|-----------------|----------|------|
| å†™å…¥æ€§èƒ½ | 8.5M points/s | 2M points/s | 4.25x |
| æŸ¥è¯¢æ€§èƒ½ | 3.2K queries/s | 1.2K queries/s | 2.7x |
| å†…å­˜ä½¿ç”¨ | 16GB | 32GB | 2x |
| ç£ç›˜ä½¿ç”¨ | 1GB/day | 3GB/day | 3x |
| é›†ç¾¤å¤æ‚åº¦ | ç®€å• | å¤æ‚ | é«˜ |
| è¿ç»´æˆæœ¬ | ä½ | é«˜ | é«˜ |

### æˆæœ¬æ•ˆç›Šåˆ†æ

| åœºæ™¯ | VictoriaMetricsæˆæœ¬ | Prometheusæˆæœ¬ | èŠ‚çœæ¯”ä¾‹ |
|------|---------------------|----------------|----------|
| å°å‹éƒ¨ç½² (10K series) | $100/æœˆ | $150/æœˆ | 33% |
| ä¸­å‹éƒ¨ç½² (100K series) | $500/æœˆ | $1200/æœˆ | 58% |
| å¤§å‹éƒ¨ç½² (1M series) | $2000/æœˆ | $8000/æœˆ | 75% |
| ä¼ä¸šçº§éƒ¨ç½² (10M series) | $8000/æœˆ | $50000/æœˆ | 84% |

## ğŸ’¡ ä¼˜åŒ–å»ºè®®

### ç¡¬ä»¶ä¼˜åŒ–

1. **CPUä¼˜åŒ–**
   ```bash
   # è®¾ç½®CPUäº²å’Œæ€§
   taskset -c 0-7 victoriametrics
   
   # å¯ç”¨CPUæ€§èƒ½æ¨¡å¼
   echo performance > /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor
   ```

2. **å†…å­˜ä¼˜åŒ–**
   ```bash
   # è°ƒæ•´å†…å­˜å‚æ•°
   echo 'vm.swappiness=1' >> /etc/sysctl.conf
   echo 'vm.dirty_ratio=15' >> /etc/sysctl.conf
   echo 'vm.dirty_background_ratio=5' >> /etc/sysctl.conf
   ```

3. **å­˜å‚¨ä¼˜åŒ–**
   ```bash
   # ä½¿ç”¨SSDå¹¶ä¼˜åŒ–æŒ‚è½½å‚æ•°
   mount -o noatime,nodiratime /dev/nvme0n1 /var/lib/victoriametrics
   
   # è°ƒæ•´I/Oè°ƒåº¦å™¨
   echo noop > /sys/block/nvme0n1/queue/scheduler
   ```

### è½¯ä»¶é…ç½®ä¼˜åŒ–

1. **VictoriaMetricsä¼˜åŒ–**
   ```yaml
   victoriametrics:
     args:
       - "-memory.allowedPercent=75"
       - "-search.maxConcurrentRequests=32"
       - "-search.maxQueryDuration=60s"
       - "-search.maxPointsPerTimeseries=100000"
       - "-dedup.minScrapeInterval=15s"
       - "-retentionPeriod=30d"
       - "-loggerLevel=WARN"
   ```

2. **VMAgentä¼˜åŒ–**
   ```yaml
   vmagent:
     args:
       - "-remoteWrite.maxDiskUsagePerURL=2GB"
       - "-remoteWrite.queues=32"
       - "-remoteWrite.maxBlockSize=64MB"
       - "-remoteWrite.flushInterval=3s"
       - "-memory.allowedPercent=60"
   ```

3. **Grafanaä¼˜åŒ–**
   ```ini
   [database]
   max_idle_conn = 50
   max_open_conn = 500
   
   [dataproxy]
   timeout = 60
   
   [caching]
   ttl = 600
   ```

### æŸ¥è¯¢ä¼˜åŒ–

1. **é«˜æ•ˆæŸ¥è¯¢æ¨¡å¼**
   ```promql
   # å¥½çš„æŸ¥è¯¢ - ä½¿ç”¨æ ‡ç­¾è¿‡æ»¤
   rate(http_requests_total{job="api", status="200"}[5m])
   
   # é¿å…çš„æŸ¥è¯¢ - è¿‡äºå®½æ³›
   rate(http_requests_total[5m])
   ```

2. **èšåˆä¼˜åŒ–**
   ```promql
   # å¥½çš„èšåˆ - å…ˆè¿‡æ»¤å†èšåˆ
   sum(rate(http_requests_total{job="api"}[5m])) by (status)
   
   # é¿å…çš„èšåˆ - èšåˆåè¿‡æ»¤
   sum(rate(http_requests_total[5m])) by (status, job) and on() vector(1)
   ```

## ğŸ“Š ç›‘æ§è„šæœ¬

### æ€§èƒ½ç›‘æ§è„šæœ¬

```bash
#!/bin/bash
# performance-monitor.sh - å®æ—¶æ€§èƒ½ç›‘æ§

VICTORIAMETRICS_URL="http://localhost:8428"
INTERVAL=30

echo "ğŸš€ VictoriaMetricsæ€§èƒ½ç›‘æ§å¯åŠ¨"
echo "ç›‘æ§é—´éš”: ${INTERVAL}ç§’"
echo "======================================"

while true; do
    timestamp=$(date '+%Y-%m-%d %H:%M:%S')
    echo "[$timestamp] æ€§èƒ½æŒ‡æ ‡:"
    
    # æŸ¥è¯¢QPS
    qps=$(curl -s "$VICTORIAMETRICS_URL/api/v1/query?query=rate(vm_http_requests_total[1m])" | jq -r '.data.result[0].value[1] // "0"')
    printf "  æŸ¥è¯¢QPS: %.2f\n" $qps
    
    # å†™å…¥é€Ÿç‡
    write_rate=$(curl -s "$VICTORIAMETRICS_URL/api/v1/query?query=rate(vm_rows_inserted_total[1m])" | jq -r '.data.result[0].value[1] // "0"')
    printf "  å†™å…¥é€Ÿç‡: %.0f samples/s\n" $write_rate
    
    # å†…å­˜ä½¿ç”¨
    memory_usage=$(curl -s "$VICTORIAMETRICS_URL/api/v1/query?query=vm_memory_usage_bytes" | jq -r '.data.result[0].value[1] // "0"')
    memory_mb=$(echo "scale=2; $memory_usage / 1024 / 1024" | bc)
    printf "  å†…å­˜ä½¿ç”¨: %.2f MB\n" $memory_mb
    
    # æ´»è·ƒæ—¶é—´åºåˆ—
    active_series=$(curl -s "$VICTORIAMETRICS_URL/api/v1/query?query=vm_active_timeseries" | jq -r '.data.result[0].value[1] // "0"')
    printf "  æ´»è·ƒåºåˆ—: %.0f\n" $active_series
    
    # ç£ç›˜ä½¿ç”¨
    disk_usage=$(curl -s "$VICTORIAMETRICS_URL/api/v1/query?query=vm_data_size_bytes" | jq -r '.data.result[0].value[1] // "0"')
    disk_gb=$(echo "scale=2; $disk_usage / 1024 / 1024 / 1024" | bc)
    printf "  ç£ç›˜ä½¿ç”¨: %.2f GB\n" $disk_gb
    
    echo "--------------------------------------"
    sleep $INTERVAL
done
```

### æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬

```python
#!/usr/bin/env python3
# benchmark.py - è‡ªåŠ¨åŒ–æ€§èƒ½åŸºå‡†æµ‹è¯•

import requests
import time
import json
import subprocess
import threading
from datetime import datetime

class PerformanceBenchmark:
    def __init__(self, vm_url="http://localhost:8428"):
        self.vm_url = vm_url
        self.results = {}
    
    def test_write_performance(self, series_count=100000):
        """æµ‹è¯•å†™å…¥æ€§èƒ½"""
        print(f"ğŸ”¥ å¼€å§‹å†™å…¥æ€§èƒ½æµ‹è¯• ({series_count} æ—¶é—´åºåˆ—)...")
        
        start_time = time.time()
        
        # æ‰§è¡Œå†™å…¥æµ‹è¯•
        cmd = [
            "victoriametrics-benchmark",
            f"-datasource.url={self.vm_url}",
            f"-series={series_count}",
            "-samples-per-series=1000",
            "-workers=16",
            "-batch-size=1000"
        ]
        
        try:
            result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
            end_time = time.time()
            
            # è§£æç»“æœ
            duration = end_time - start_time
            samples_per_sec = (series_count * 1000) / duration
            
            self.results['write_performance'] = {
                'series_count': series_count,
                'duration': duration,
                'samples_per_sec': samples_per_sec,
                'success': result.returncode == 0
            }
            
            print(f"  âœ… å†™å…¥æµ‹è¯•å®Œæˆ: {samples_per_sec:.0f} samples/sec")
            
        except subprocess.TimeoutExpired:
            print("  âŒ å†™å…¥æµ‹è¯•è¶…æ—¶")
            self.results['write_performance'] = {'error': 'timeout'}
    
    def test_query_performance(self, query_count=1000):
        """æµ‹è¯•æŸ¥è¯¢æ€§èƒ½"""
        print(f"ğŸ” å¼€å§‹æŸ¥è¯¢æ€§èƒ½æµ‹è¯• ({query_count} æŸ¥è¯¢)...")
        
        queries = [
            "up",
            "rate(http_requests_total[5m])",
            "sum(rate(cpu_usage[5m])) by (instance)",
            "histogram_quantile(0.95, rate(http_duration_seconds_bucket[5m]))"
        ]
        
        latencies = []
        errors = 0
        
        start_time = time.time()
        
        for i in range(query_count):
            query = queries[i % len(queries)]
            
            try:
                query_start = time.time()
                response = requests.get(
                    f"{self.vm_url}/api/v1/query",
                    params={'query': query},
                    timeout=30
                )
                query_end = time.time()
                
                if response.status_code == 200:
                    latencies.append((query_end - query_start) * 1000)  # ms
                else:
                    errors += 1
                    
            except Exception:
                errors += 1
        
        end_time = time.time()
        
        # è®¡ç®—ç»Ÿè®¡ä¿¡æ¯
        if latencies:
            latencies.sort()
            p50 = latencies[len(latencies) // 2]
            p95 = latencies[int(len(latencies) * 0.95)]
            p99 = latencies[int(len(latencies) * 0.99)]
            avg_latency = sum(latencies) / len(latencies)
            qps = query_count / (end_time - start_time)
            
            self.results['query_performance'] = {
                'query_count': query_count,
                'qps': qps,
                'avg_latency': avg_latency,
                'p50_latency': p50,
                'p95_latency': p95,
                'p99_latency': p99,
                'error_rate': errors / query_count * 100
            }
            
            print(f"  âœ… æŸ¥è¯¢æµ‹è¯•å®Œæˆ: {qps:.0f} QPS, P95å»¶è¿Ÿ: {p95:.1f}ms")
        else:
            print("  âŒ æŸ¥è¯¢æµ‹è¯•å¤±è´¥")
            self.results['query_performance'] = {'error': 'all_failed'}
    
    def test_resource_usage(self, duration=60):
        """æµ‹è¯•èµ„æºä½¿ç”¨æƒ…å†µ"""
        print(f"ğŸ“Š å¼€å§‹èµ„æºä½¿ç”¨æµ‹è¯• ({duration}ç§’)...")
        
        metrics = []
        
        def collect_metrics():
            for _ in range(duration):
                try:
                    # è·å–å†…å­˜ä½¿ç”¨
                    memory_resp = requests.get(
                        f"{self.vm_url}/api/v1/query",
                        params={'query': 'vm_memory_usage_bytes'}
                    )
                    
                    # è·å–æ´»è·ƒæ—¶é—´åºåˆ—
                    series_resp = requests.get(
                        f"{self.vm_url}/api/v1/query",
                        params={'query': 'vm_active_timeseries'}
                    )
                    
                    if memory_resp.status_code == 200 and series_resp.status_code == 200:
                        memory_data = memory_resp.json()
                        series_data = series_resp.json()
                        
                        if (memory_data['data']['result'] and 
                            series_data['data']['result']):
                            
                            memory_bytes = float(memory_data['data']['result'][0]['value'][1])
                            active_series = float(series_data['data']['result'][0]['value'][1])
                            
                            metrics.append({
                                'timestamp': time.time(),
                                'memory_mb': memory_bytes / 1024 / 1024,
                                'active_series': active_series
                            })
                    
                except Exception as e:
                    print(f"  âš ï¸ æŒ‡æ ‡æ”¶é›†é”™è¯¯: {e}")
                
                time.sleep(1)
        
        # å¯åŠ¨æŒ‡æ ‡æ”¶é›†çº¿ç¨‹
        thread = threading.Thread(target=collect_metrics)
        thread.start()
        thread.join()
        
        if metrics:
            avg_memory = sum(m['memory_mb'] for m in metrics) / len(metrics)
            max_memory = max(m['memory_mb'] for m in metrics)
            avg_series = sum(m['active_series'] for m in metrics) / len(metrics)
            
            self.results['resource_usage'] = {
                'duration': duration,
                'avg_memory_mb': avg_memory,
                'max_memory_mb': max_memory,
                'avg_active_series': avg_series,
                'sample_count': len(metrics)
            }
            
            print(f"  âœ… èµ„æºæµ‹è¯•å®Œæˆ: å¹³å‡å†…å­˜ {avg_memory:.1f}MB, æ´»è·ƒåºåˆ— {avg_series:.0f}")
        else:
            print("  âŒ èµ„æºæµ‹è¯•å¤±è´¥")
            self.results['resource_usage'] = {'error': 'no_data'}
    
    def run_full_benchmark(self):
        """è¿è¡Œå®Œæ•´åŸºå‡†æµ‹è¯•"""
        print("ğŸš€ å¼€å§‹å®Œæ•´æ€§èƒ½åŸºå‡†æµ‹è¯•")
        print("======================================")
        
        # å†™å…¥æ€§èƒ½æµ‹è¯•
        self.test_write_performance(100000)
        time.sleep(10)  # ç­‰å¾…ç³»ç»Ÿç¨³å®š
        
        # æŸ¥è¯¢æ€§èƒ½æµ‹è¯•
        self.test_query_performance(1000)
        time.sleep(10)
        
        # èµ„æºä½¿ç”¨æµ‹è¯•
        self.test_resource_usage(60)
        
        # ç”ŸæˆæŠ¥å‘Š
        self.generate_report()
    
    def generate_report(self):
        """ç”Ÿæˆæµ‹è¯•æŠ¥å‘Š"""
        print("\nğŸ“‹ æ€§èƒ½åŸºå‡†æµ‹è¯•æŠ¥å‘Š")
        print("======================================")
        
        # å†™å…¥æ€§èƒ½æŠ¥å‘Š
        if 'write_performance' in self.results:
            wp = self.results['write_performance']
            if 'samples_per_sec' in wp:
                print(f"ğŸ“ å†™å…¥æ€§èƒ½:")
                print(f"  æ—¶é—´åºåˆ—æ•°: {wp['series_count']:,}")
                print(f"  å†™å…¥é€Ÿç‡: {wp['samples_per_sec']:,.0f} samples/sec")
                print(f"  æµ‹è¯•æ—¶é•¿: {wp['duration']:.1f}ç§’")
        
        # æŸ¥è¯¢æ€§èƒ½æŠ¥å‘Š
        if 'query_performance' in self.results:
            qp = self.results['query_performance']
            if 'qps' in qp:
                print(f"\nğŸ” æŸ¥è¯¢æ€§èƒ½:")
                print(f"  æŸ¥è¯¢æ•°é‡: {qp['query_count']:,}")
                print(f"  æŸ¥è¯¢QPS: {qp['qps']:.0f}")
                print(f"  å¹³å‡å»¶è¿Ÿ: {qp['avg_latency']:.1f}ms")
                print(f"  P95å»¶è¿Ÿ: {qp['p95_latency']:.1f}ms")
                print(f"  P99å»¶è¿Ÿ: {qp['p99_latency']:.1f}ms")
                print(f"  é”™è¯¯ç‡: {qp['error_rate']:.2f}%")
        
        # èµ„æºä½¿ç”¨æŠ¥å‘Š
        if 'resource_usage' in self.results:
            ru = self.results['resource_usage']
            if 'avg_memory_mb' in ru:
                print(f"\nğŸ“Š èµ„æºä½¿ç”¨:")
                print(f"  å¹³å‡å†…å­˜: {ru['avg_memory_mb']:.1f}MB")
                print(f"  å³°å€¼å†…å­˜: {ru['max_memory_mb']:.1f}MB")
                print(f"  æ´»è·ƒåºåˆ—: {ru['avg_active_series']:.0f}")
        
        # ä¿å­˜ç»“æœåˆ°æ–‡ä»¶
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"benchmark_results_{timestamp}.json"
        
        with open(filename, 'w') as f:
            json.dump(self.results, f, indent=2)
        
        print(f"\nğŸ’¾ è¯¦ç»†ç»“æœå·²ä¿å­˜åˆ°: {filename}")
        print("======================================")

if __name__ == "__main__":
    benchmark = PerformanceBenchmark()
    benchmark.run_full_benchmark()
```

---

## ğŸ“š ç›¸å…³æ–‡æ¡£

- [å¿«é€Ÿå¼€å§‹æŒ‡å—](./quick-start.md)
- [APIå‚è€ƒæ–‡æ¡£](./api-reference.md)
- [æ•…éšœæ’é™¤æŒ‡å—](./troubleshooting.md)
- [ç³»ç»Ÿæ¶æ„æ–‡æ¡£](./system-architecture.md)

---

**æ€§èƒ½åŸºå‡†æŠ¥å‘Šç‰ˆæœ¬**: v1.0.0  
**æµ‹è¯•æ—¥æœŸ**: 2024-01-20  
**æµ‹è¯•ç¯å¢ƒ**: ç”Ÿäº§çº§ç¡¬ä»¶é…ç½®  
**ç»´æŠ¤è€…**: æ€§èƒ½æµ‹è¯•å›¢é˜Ÿ